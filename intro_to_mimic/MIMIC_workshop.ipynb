{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-III Introduction Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workshop coordinators: Dr Matthieu Komorowski, Dr Shabbir Syed-Abdul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll explore the data of a single patient, before building a simple predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Exploring the trajectory of a single patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import some tools for working with data in Python. \n",
    "- NumPy is for working with numbers\n",
    "- Pandas is for analysing data\n",
    "- MatPlotLib is for making plots\n",
    "- Sqlite3 to connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use the sqlite3 library to connect to the MIMIC database\n",
    "- **Update the file path to your local folder!!**\n",
    "- Once the connection is established, we'll run a simple SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MIMIC database\n",
    "conn = sqlite3.connect('C:\\Users\\Matthieu\\mimic_workshop-master\\data\\mimicdata.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our test query\n",
    "test_query = \"\"\"\n",
    "SELECT subject_id, hadm_id, admittime, dischtime, admission_type, diagnosis\n",
    "FROM admissions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the query and assign the results to a variable\n",
    "test = pd.read_sql_query(test_query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the chartevents data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The chartevents table contains data charted at the patient bedside. It includes variables such as heart rate, respiratory rate, temperature, and so on.\n",
    "- We'll begin by loading the chartevents data for a single patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT de.icustay_id\n",
    "  , round((strftime('%s',de.charttime)-strftime('%s',ie.intime))/60.0/60.0+0.5) as HOURS\n",
    "  , di.label\n",
    "  , de.value\n",
    "  , de.valuenum\n",
    "  , de.uom\n",
    "FROM chartevents de\n",
    "INNER join d_items di\n",
    "ON de.itemid = di.itemid\n",
    "INNER join icustays ie\n",
    "ON de.icustay_id = ie.icustay_id\n",
    "WHERE de.icustay_id = 252522\n",
    "ORDER BY charttime;\n",
    "\"\"\"\n",
    "\n",
    "ce = pd.read_sql_query(query,conn)\n",
    "\n",
    "\n",
    "# OPTION 2: load chartevents from a CSV file\n",
    "# ce = pd.read_csv('data/example_chartevents.csv', index_col='HOURSSINCEADMISSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "# Use 'head' to limit the number of rows returned\n",
    "ce.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the patient's heart rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can select individual columns using the column name. \n",
    "- For example, if we want to select just the label column, we write **```ce.LABEL```** or alternatively **```ce['LABEL']```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column from the chartevents data we extracted \n",
    "ce['LABEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In a similar way, we can select rows from data using indexes. \n",
    "- For example, to select rows where the label is equal to 'Heart Rate', we would create an index using **```[ce.LABEL=='Heart Rate']```** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the heart rate rows using an index\n",
    "ce[ce.LABEL=='Heart Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 1: How did the patients heart rate change over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the methods described above to select our data of interest, we can create our x and y axis values to create a time series plot of heart rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which time stamps have a corresponding heart rate measurement?\n",
    "print ce.index[ce.LABEL=='Heart Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set x equal to the times\n",
    "x_hr = ce.HOURS[ce.LABEL=='Heart Rate']\n",
    "\n",
    "# Set y equal to the heart rates\n",
    "y_hr = ce.VALUENUM[ce.LABEL=='Heart Rate']\n",
    "\n",
    "# Plot time against heart rate\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(x_hr,y_hr)\n",
    "\n",
    "\n",
    "plt.xlabel('Time',fontsize=16)\n",
    "plt.ylabel('Heart rate',fontsize=16)\n",
    "plt.title('Heart rate over time from admission to the intensive care unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "\n",
    "* What is happening to this patient's heart rate?\n",
    "* Plot respiratory rate over time for the patient.\n",
    "* Is there anything unusual about the patient's respiratory rate?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did the patient's vital signs breach any alarm thresholds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alarm systems in the intensive care unit are commonly based on high and low thresholds defined by the carer.\n",
    "- False alarms are often a problem and so thresholds may be set arbitrarily to reduce alarms.\n",
    "- As a result, alarm settings carry limited information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2: Respiratory rate and alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(ce.HOURS[ce.LABEL=='Respiratory Rate'], \n",
    "         ce.VALUENUM[ce.LABEL=='Respiratory Rate'],\n",
    "         'k+', markersize=10, linewidth=4)\n",
    "\n",
    "plt.plot(ce.HOURS[ce.LABEL=='Resp Alarm - High'], \n",
    "         ce.VALUENUM[ce.LABEL=='Resp Alarm - High'],\n",
    "         'm--')\n",
    "\n",
    "plt.plot(ce.HOURS[ce.LABEL=='Resp Alarm - Low'], \n",
    "         ce.VALUENUM[ce.LABEL=='Resp Alarm - Low'],\n",
    "         'm--')\n",
    "\n",
    "plt.xlabel('Time',fontsize=16)\n",
    "plt.ylabel('Respiratory rate',fontsize=16)\n",
    "plt.title('Respiratory rate over time from admission, with upper and lower alarm thresholds')\n",
    "plt.ylim(0,55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "\n",
    "- Based on the data, does it look like the alarms would have triggered for this patient?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What was the patient's level of consciousness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Glasgow Coma Scale (GCS) is a measure of consciousness.\n",
    "- It is commonly used for monitoring patients in the intensive care unit. \n",
    "- It consists of three components: eye response; verbal response; motor response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the GCS eye response data\n",
    "ce[ce.LABEL=='GCS - Eye Opening'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 3: GCS over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the size of the figure\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Set x equal to the times\n",
    "x_hr = ce.HOURS[ce.LABEL=='Heart Rate']\n",
    "\n",
    "# Set y equal to the heart rates\n",
    "y_hr = ce.VALUENUM[ce.LABEL=='Heart Rate']\n",
    "\n",
    "\n",
    "plt.plot(x_hr,y_hr)\n",
    "\n",
    "plt.plot(ce.HOURS[ce.LABEL=='Respiratory Rate'], \n",
    "         ce.VALUENUM[ce.LABEL=='Respiratory Rate'],\n",
    "         'k', markersize=6)\n",
    "\n",
    "# Add a text label to the y-axis\n",
    "plt.text(-20,155,'GCS - Eye Opening',fontsize=14)\n",
    "plt.text(-20,150,'GCS - Motor Response',fontsize=14)\n",
    "plt.text(-20,145,'GCS - Verbal Response',fontsize=14)   \n",
    "\n",
    "# Iterate over list of GCS labels, plotting around 1 in 10 to avoid overlap\n",
    "for i, txt in enumerate(ce.VALUE[ce.LABEL=='GCS - Eye Opening'].values):\n",
    "    if np.mod(i,6)==0 and i < 65:\n",
    "        plt.annotate(txt, (ce.HOURS[ce.LABEL=='GCS - Eye Opening'].values[i],155),fontsize=14)\n",
    "        \n",
    "for i, txt in enumerate(ce.VALUE[ce.LABEL=='GCS - Motor Response'].values):\n",
    "    if np.mod(i,6)==0 and i < 65:\n",
    "        plt.annotate(txt, (ce.HOURS[ce.LABEL=='GCS - Motor Response'].values[i],150),fontsize=14)\n",
    "\n",
    "for i, txt in enumerate(ce.VALUE[ce.LABEL=='GCS - Verbal Response'].values):\n",
    "    if np.mod(i,6)==0 and i < 65:\n",
    "        plt.annotate(txt, (ce.HOURS[ce.LABEL=='GCS - Verbal Response'].values[i],145),fontsize=14)\n",
    "\n",
    "plt.title('Vital signs and Glasgow Coma Scale over time from admission',fontsize=16)\n",
    "\n",
    "plt.xlabel('Time (hours)',fontsize=16)\n",
    "plt.ylabel('Heart rate or GCS',fontsize=16)\n",
    "plt.ylim(10,165)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "\n",
    "- How is the patient's consciousness changing over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the patient's other vital signs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise on a single plot several vital signs for out patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 4: Were the patient's other vital signs stable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.plot(ce.index[ce.LABEL=='Heart Rate'], \n",
    "         ce.VALUENUM[ce.LABEL=='Heart Rate'],\n",
    "         'rx', markersize=8, label='HR')\n",
    "\n",
    "plt.plot(ce.index[ce.LABEL=='O2 saturation pulseoxymetry'], \n",
    "         ce.VALUENUM[ce.LABEL=='O2 saturation pulseoxymetry'], \n",
    "         'g.', markersize=8, label='O2')\n",
    "\n",
    "plt.plot(ce.index[ce.LABEL=='Non Invasive Blood Pressure mean'], \n",
    "         ce.VALUENUM[ce.LABEL=='Non Invasive Blood Pressure mean'], \n",
    "         'bv', markersize=8, label='MAP')\n",
    "\n",
    "plt.plot(ce.index[ce.LABEL=='Respiratory Rate'], \n",
    "         ce.VALUENUM[ce.LABEL=='Respiratory Rate'], \n",
    "         'k+', markersize=8, label='RR')\n",
    "\n",
    "plt.title('Vital signs over time from admission')\n",
    "plt.ylim(0,130)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas 'read_csv function' again, we'll now load the labevents data.\n",
    "This data corresponds to measurements made in a laboratory - usually on a sample of patient blood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: load labevents data using the database connection\n",
    "query = \"\"\"\n",
    "SELECT de.subject_id\n",
    "  , de.charttime\n",
    "  , di.label, de.value, de.valuenum\n",
    "  , de.uom\n",
    "FROM labevents de\n",
    "INNER JOIN d_labitems di\n",
    "  ON de.itemid = di.itemid\n",
    "where de.subject_id = 40080\n",
    "\"\"\"\n",
    "\n",
    "le = pd.read_sql_query(query,conn)\n",
    "\n",
    "# OPTION 2: load labevents from the CSV file\n",
    "# le = pd.read_csv('data/example_labevents.csv', index_col='HOURSSINCEADMISSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the labevents data\n",
    "le.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the ioevents data\n",
    "le[le.LABEL=='HEMOGLOBIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLot 5: hemoglobin and hematocrit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.plot(le.index[le.LABEL=='HEMATOCRIT'], \n",
    "         le.VALUENUM[le.LABEL=='HEMATOCRIT'], \n",
    "         'go', markersize=6, label='Haematocrit')\n",
    "\n",
    "plt.plot(le.index[le.LABEL=='HEMOGLOBIN'], \n",
    "         le.VALUENUM[le.LABEL=='HEMOGLOBIN'], \n",
    "         'bv', markersize=8, label='Hemoglobin')\n",
    "\n",
    "plt.title('Laboratory measurements over time from admission')\n",
    "plt.ylim(0,38)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Building a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the MIMIC demo dataset only contains data from 8 patients, all non-survivors, this dataset is not suitable to build mortality prediction models.\n",
    "- Instead, let's try something with the available data: can we predict SpO2 given arterial pO2 and mean blood pressure?\n",
    "- First, let’s extract a suitable dataset. We’ll run 3 sub-queries (one for each feature) then combine them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "with t1 as -- all time steps\n",
    "(\n",
    "\n",
    "SELECT distinct de.subject_id\n",
    "  , round((strftime('%s',de.charttime)-strftime('%s',ie.intime))/60.0/120.0) as HOURS\n",
    "FROM chartevents de\n",
    "INNER join icustays ie\n",
    "ON de.subject_id = ie.subject_id\n",
    "order by de.subject_id, charttime\n",
    "\n",
    "), t2 as  -- po2\n",
    "(\n",
    "SELECT de.subject_id\n",
    "  --, de.charttime\n",
    "  , round((strftime('%s',de.charttime)-strftime('%s',ie.intime))/60.0/120.0+1) as HOURS\n",
    " -- , di.label, de.value\n",
    "  ,de.valuenum as po2\n",
    "  --, de.uom\n",
    "FROM labevents de\n",
    "INNER JOIN d_labitems di\n",
    "  ON de.itemid = di.itemid\n",
    "INNER join icustays ie\n",
    "ON de.subject_id = ie.subject_id\n",
    "where label = 'PO2'\n",
    "order by de.subject_id, hours\n",
    "\n",
    "), t3 as  -- spo2\n",
    "(\n",
    "with t1 as\n",
    "(SELECT de.subject_id\n",
    "  , round((strftime('%s',de.charttime)-strftime('%s',ie.intime))/60.0/120.0+1) as HOURS\n",
    "  , de.valuenum\n",
    "FROM chartevents de\n",
    "INNER join d_items di\n",
    "ON de.itemid = di.itemid\n",
    "INNER join icustays ie\n",
    "ON de.subject_id = ie.subject_id\n",
    "WHERE label = 'O2 saturation pulseoxymetry'\n",
    "ORDER BY charttime)\n",
    "select subject_id, hours, avg(valuenum) as spo2\n",
    "from t1\n",
    "group by subject_id, hours\n",
    "order by subject_id, hours\n",
    "), t4 as -- map\n",
    "(\n",
    "with t1 as\n",
    "(SELECT de.subject_id\n",
    "  , round((strftime('%s',de.charttime)-strftime('%s',ie.intime))/60.0/120.0+1) as HOURS\n",
    "  , de.valuenum\n",
    "FROM chartevents de\n",
    "INNER join d_items di\n",
    "ON de.itemid = di.itemid\n",
    "INNER join icustays ie\n",
    "ON de.icustay_id = ie.icustay_id\n",
    "WHERE label = 'Non Invasive Blood Pressure mean'\n",
    "ORDER BY charttime)\n",
    "select subject_id, hours, avg(valuenum) as map\n",
    "from t1\n",
    "group by subject_id, hours\n",
    "order by subject_id, hours\n",
    "\n",
    ")\n",
    "\n",
    "select t1.*, t2.po2 as po2,t4.map as map, t3.spo2 as spo2\n",
    "from t1, t2, t3, t4\n",
    "where t1.subject_id=t2.subject_id and t1.subject_id=t3.subject_id   and t1.subject_id=t4.subject_id   and t4.hours>=t1.hours-2 and t4.hours<=t1.hours+2  and t2.hours>=t1.hours-2  and t2.hours<=t1.hours+2 and t1.hours=t3.hours\"\"\"\n",
    "    \n",
    "# Run the query  \n",
    "uo = pd.read_sql_query(query,conn)\n",
    "\n",
    "# Save the correct columns into X (input) and Y (output) variables\n",
    "X=uo.drop('subject_id', axis = 1)\n",
    "X=X.drop('HOURS',axis=1)\n",
    "Y=uo.spo2\n",
    "# Save the name of the column headers \n",
    "feature_list = list(X.columns)\n",
    "# Visualise the dataset created \n",
    "uo.head()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to train and test any statistical model on separate data, otherwise the model performance may be overestimated. So, let’s split the dataset into training and testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "Xtrain, Xtest, Ytrain , Ytest = train_test_split(X,Y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "print('Training Features Shape:', Xtrain.shape)\n",
    "print('Training Labels Shape:', Ytrain.shape)\n",
    "print('Testing Features Shape:', Xtest.shape)\n",
    "print('Testing Labels Shape:', Ytest.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve prepared the data, let’s build the predictive model. We’ll be using a random forest model, and learn the relationship between input data (pO2 and MAP) and the output (SpO2). Then, we’ll try the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.neighbors  import KNeighborsClassifier\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Build a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain,Ytrain.astype('int'))\n",
    "\n",
    "# Use the random forest predict method on the test data\n",
    "predictions = rf.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s assess the performance of the model we built. We can measure the absolute error between actual and predicted values, and the mean absolute percentage error (MAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - Ytest)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), '% of SpO2')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / Ytest)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 6: Actual versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual versus predicted values\n",
    "plt.scatter(Xtest.po2, Ytest, c=\"g\", alpha=0.5, label=\"True test data\")\n",
    "plt.scatter(Xtest.po2, predictions, c=\"r\", alpha=0.5, label=\"Predicted data\")\n",
    "\n",
    "plt.xlabel(\"pO2\")\n",
    "plt.ylabel(\"spO2\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our workshop. To summarise, we gained insight into MIMIC-III, the publicly accessible critical care database. We explored raw patient data with SQL queries, extracted and analysed the data of a single patient and built a simple predictive model.\n",
    "\n",
    "If after this workshop you would like to gain access to the full MIMIC-III dataset, which contains rich data for over 40,000 patients, please see: https://mimic.physionet.org/gettingstarted/access/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
